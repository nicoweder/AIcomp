{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2826930-cd2c-43f0-b5a6-4425a0d090c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /opt/conda/lib/python3.12/site-packages (from xgboost) (2.21.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from xgboost) (1.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e59f963-a253-4bb4-95e0-7b9ccdeb4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from event_detection_ap import score, ParticipantVisibleError\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from datetime import datetime\n",
    "import gc\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a615f3fb-a079-49e1-a7fd-cac1ffdd4c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "N_SPLITS = 5\n",
    "\n",
    "\n",
    "# Dateipfade\n",
    "DATA_PATH = \"processed/merged_dff_gold84_V3.parquet\"\n",
    "\n",
    "EVENTS_PATH = \"processed/event_cleaned.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02030b7-ace9-400c-a889-1fcadcb06ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_predictions(y_probs, threshold):\n",
    "    # Apply threshold to the probabilities\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    return np.where(y_pred == 1)[0]  # Return indices where predictions are 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111dde1a-439e-440f-ab1c-6f99e27bcb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def candidate_windowing(df):\n",
    "    df[\"step_int\"] = df[\"step\"].astype(int)\n",
    "    df[\"step_offset\"] = df.groupby(\"series_id\")[\"step_int\"].transform(lambda x: x - x.min())\n",
    "    return df[df[\"step_offset\"] % 3 == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b94b42-7847-45fe-843c-491ed21fd13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_labels(df, radius=4):\n",
    "    def expand_group(group):\n",
    "        target_array = group[\"target\"].values.copy()\n",
    "        shifted_targets = {}\n",
    "        for shift in range(1, radius + 1):\n",
    "            shifted_targets[f\"minus_{shift}\"] = group[\"target\"].shift(-shift, fill_value=0).values\n",
    "            shifted_targets[f\"plus_{shift}\"] = group[\"target\"].shift(shift, fill_value=0).values\n",
    "\n",
    "        # apply shifts without fragmenting the dataframe\n",
    "        for values in shifted_targets.values():\n",
    "            target_array |= values\n",
    "\n",
    "        group = group.copy()  \n",
    "        group[\"target\"] = target_array\n",
    "        return group\n",
    "\n",
    "    df = df.groupby(\"series_id\", group_keys=False).apply(expand_group)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64eb9aee-5abf-4c43-94aa-8ab6d4c5a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48dfcb03-ac16-4fcd-870a-47e038eadad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set\n",
    "final_preset = [\n",
    "    \"anglez\", \"enmo\", \"hour\", \"minute\", \"is_night\", \"is_weekend\",\n",
    "    \"anglez_delta\", \"anglez_lag_1\", \"enmo_lag_1\",\n",
    "    \"anglez_mean_60s\", \"enmo_mean_60s\", \"enmo_std_60s\",\n",
    "    \"anglez_min_60s\", \"enmo_max_60s\",\n",
    "    \"enmo_cumulative_60s\", \"enmo_sma_60s\",\n",
    "    \"enmo_mean_12s_lag_1\", \"anglez_std_60s_lag_1\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40bafd32-7c32-4424-95c7-29ba16d28851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "missing_features = [feat for feat in final_preset if feat not in df.columns]\n",
    "print(missing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21d12013-04e0-4eea-b6de-84a0f83c2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_simple(\n",
    "    feature_set,\n",
    "    radius=6,\n",
    "    model_params=None,\n",
    "    save_results=True\n",
    "):\n",
    "    df_exp = candidate_windowing(df)\n",
    "    df_exp = expand_labels(df_exp, radius=radius)\n",
    "    X = df_exp[feature_set].astype(np.float32)\n",
    "    y = df_exp[\"target\"]\n",
    "    groups = df_exp[\"series_id\"]\n",
    "    meta = df_exp[[\"series_id\", \"step\"]].copy()\n",
    "\n",
    "    gkf = GroupKFold(n_splits=N_SPLITS)\n",
    "\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    all_probs = []\n",
    "    all_meta = []\n",
    "    all_best_thresholds = []  # Store the best threshold for each fold\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        meta_val = meta.iloc[val_idx]\n",
    "\n",
    "        if model_params is None:\n",
    "            model_params = {\n",
    "                \"objective\": \"binary:logistic\",\n",
    "                \"n_estimators\": 200,\n",
    "                \"max_depth\": 6,\n",
    "                \"learning_rate\": 0.05,\n",
    "                \"eval_metric\": \"logloss\",\n",
    "                \"tree_method\": \"hist\",\n",
    "                \"scale_pos_weight\": 170,\n",
    "                \"random_state\": 42,\n",
    "            }\n",
    "\n",
    "        model = xgb.XGBClassifier(**model_params)\n",
    "        weights = compute_sample_weight(\"balanced\", y_train)\n",
    "        model.fit(X_train, y_train, sample_weight=weights)\n",
    "\n",
    "        y_probs = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        # Threshold optimization\n",
    "        prec, rec, thresholds_pr = precision_recall_curve(y_val, y_probs)\n",
    "        \n",
    "        \n",
    "        valid = rec[:-1] >= 0.85  # -1 because rec is longer than thresholds\n",
    "        if np.any(valid):\n",
    "            prec_valid = prec[:-1][valid]\n",
    "            thresholds_valid = thresholds_pr[valid]\n",
    "            best_idx = np.argmax(prec_valid)\n",
    "            best_threshold = thresholds_valid[best_idx]\n",
    "        else:\n",
    "            # Fallback: choose threshold with best F1 score\n",
    "            f1s = 2 * (prec * rec) / (prec + rec + 1e-8)\n",
    "            best_threshold = thresholds_pr[np.argmax(f1s)]\n",
    "\n",
    "        all_best_thresholds.append(best_threshold)\n",
    "\n",
    "        # Apply best threshold\n",
    "        y_pred = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "        all_probs.extend(y_probs)\n",
    "        all_preds.extend(y_pred)\n",
    "        all_true.extend(y_val)\n",
    "        all_meta.append(meta_val)\n",
    "\n",
    "        # Clean up memory\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    precision = precision_score(all_true, all_preds)\n",
    "    recall = recall_score(all_true, all_preds)\n",
    "    f1 = f1_score(all_true, all_preds)\n",
    "\n",
    "    # Calculate global threshold (average across folds)\n",
    "    global_threshold = np.mean(all_best_thresholds)\n",
    "    print(f\"\\n⮕ Global threshold (average from all folds): {global_threshold:.4f}\")\n",
    "\n",
    "    if save_results:\n",
    "        results_df = pd.concat(all_meta).copy()\n",
    "        results_df[\"true_label\"] = all_true\n",
    "        results_df[\"pred_label\"] = all_preds\n",
    "        results_df[\"score\"] = all_probs\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"results/model_preds_radius{radius}_{timestamp}.csv\"\n",
    "        results_df.to_csv(filename, index=False)\n",
    "        print(f\"Saved predictions to: {filename}\")\n",
    "\n",
    "    return precision, recall, f1, global_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "febce634-aa32-4d7e-86db-ca739c792e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16418/4175275608.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"series_id\", group_keys=False).apply(expand_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⮕ Global threshold (average from all folds): 0.9127\n",
      "Saved predictions to: results/model_preds_radius12_20250429_155041.csv\n",
      "[base] radius=12 | best threshold=0.91 | n_estimators=300 | max_depth=4 | lr=0.050 | spw=10 → Precision=0.037, Recall= 0.850, F1=0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16418/4175275608.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"series_id\", group_keys=False).apply(expand_group)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 38\u001b[0m\n\u001b[1;32m     22\u001b[0m model_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: n_estimators,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     35\u001b[0m }\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# IMPORTANT: run_experiment_simple no longer expects a threshold input\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m p, r_, f, best_threshold \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] radius=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | best threshold=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_threshold\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_estimators\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | max_depth=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_depth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearning_rate\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | spw=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscale_pos_weight\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m → \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Save if precision is the best so far for this radius\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 41\u001b[0m, in \u001b[0;36mrun_experiment_simple\u001b[0;34m(feature_set, radius, model_params, save_results)\u001b[0m\n\u001b[1;32m     39\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_params)\n\u001b[1;32m     40\u001b[0m weights \u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_train)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m y_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Threshold optimization\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/xgboost/sklearn.py:1682\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1660\u001b[0m model, metric, params, feature_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[1;32m   1661\u001b[0m     xgb_model, params, feature_weights\n\u001b[1;32m   1662\u001b[0m )\n\u001b[1;32m   1663\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1664\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1665\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1680\u001b[0m )\n\u001b[0;32m-> 1682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/xgboost/core.py:2247\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2246\u001b[0m     _check_call(\n\u001b[0;32m-> 2247\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2250\u001b[0m     )\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2252\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_sets = {\n",
    "    \"base\": final_preset\n",
    "}\n",
    "\n",
    "radii = [12, 30, 50]\n",
    "n_estimators_list = [300, 800, 1500]\n",
    "max_depth_list = [4, 8]\n",
    "learning_rate_list = [0.05, 0.02, 0.005]\n",
    "scale_pos_weight_list = [10, 100]\n",
    "\n",
    "best_results = {}  # Store best results for each radius\n",
    "\n",
    "for name, feats in feature_sets.items():\n",
    "    for r in radii:\n",
    "        best_precision = -1  \n",
    "        best_entry = None\n",
    "\n",
    "        for n_estimators in n_estimators_list:\n",
    "            for max_depth in max_depth_list:\n",
    "                for learning_rate in learning_rate_list:\n",
    "                    for scale_pos_weight in scale_pos_weight_list:\n",
    "                        model_params = {\n",
    "                            \"objective\": \"binary:logistic\",\n",
    "                            \"n_estimators\": n_estimators,\n",
    "                            \"max_depth\": max_depth,\n",
    "                            \"learning_rate\": learning_rate,\n",
    "                            \"eval_metric\": \"logloss\",\n",
    "                            \"tree_method\": \"hist\",\n",
    "                            \"scale_pos_weight\": scale_pos_weight,\n",
    "                            \"subsample\": 0.8,\n",
    "                            \"colsample_bytree\": 0.8,\n",
    "                            \"gamma\": 1,\n",
    "                            \"min_child_weight\": 5,\n",
    "                            \"random_state\": 42,\n",
    "                        }\n",
    "\n",
    "                        # IMPORTANT: run_experiment_simple no longer expects a threshold input\n",
    "                        p, r_, f, best_threshold = run_experiment_simple(\n",
    "                            feats,\n",
    "                            radius=r,\n",
    "                            model_params=model_params\n",
    "                        )\n",
    "\n",
    "                        print(f\"[{name}] radius={r} | best threshold={best_threshold:.2f} | \"\n",
    "                              f\"n_estimators={n_estimators} | max_depth={max_depth} | \"\n",
    "                              f\"lr={learning_rate:.3f} | spw={scale_pos_weight} → \"\n",
    "                              f\"Precision={p:.3f}, Recall={r_: .3f}, F1={f:.3f}\")\n",
    "\n",
    "                        # Save if precision is the best so far for this radius\n",
    "                        if p > best_precision:\n",
    "                            best_precision = p\n",
    "                            best_entry = {\n",
    "                                \"radius\": r,\n",
    "                                \"threshold\": best_threshold,\n",
    "                                \"n_estimators\": n_estimators,\n",
    "                                \"max_depth\": max_depth,\n",
    "                                \"learning_rate\": learning_rate,\n",
    "                                \"scale_pos_weight\": scale_pos_weight,\n",
    "                                \"precision\": p,\n",
    "                                \"recall\": r_,\n",
    "                                \"f1\": f\n",
    "                            }\n",
    "\n",
    "        # After all parameter combinations for a given radius\n",
    "        best_results[r] = best_entry\n",
    "\n",
    "# Print summary of best configurations per radius\n",
    "print(\"\\n🏆 Best results per radius:\")\n",
    "for radius, result in best_results.items():\n",
    "    print(f\"Radius {radius}: \"\n",
    "          f\"Precision={result['precision']:.3f}, Recall={result['recall']:.3f}, F1={result['f1']:.3f} | \"\n",
    "          f\"Params: best_threshold={result['threshold']:.2f}, \"\n",
    "          f\"n_estimators={result['n_estimators']}, max_depth={result['max_depth']}, \"\n",
    "          f\"lr={result['learning_rate']:.3f}, spw={result['scale_pos_weight']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd16ccf-134e-4390-8dea-ea7246ac0b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d832b4c-40d0-44d2-b0ef-a367db0f0f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

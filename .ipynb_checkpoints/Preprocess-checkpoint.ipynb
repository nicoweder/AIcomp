{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a23f1ba-4c1a-40ae-9514-24f75f845b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.12/site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.12/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.12/site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.12/site-packages (19.0.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install pyarrow\n",
    "!pip install matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3853049c-6686-4940-94b9-fa1549d730c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "519d8e76-be28-413b-913c-5d3b13d0bc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Lade Rohdaten...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# === 1. Load raw data ===\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müì• Lade Rohdaten...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/jovyan/AICOMP/Second/code/data/raw/train_series.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m train_events \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jovyan/AICOMP/Second/code/data/raw/train_events.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/io/parquet.py:281\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 281\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mto_pandas_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    284\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_as_manager(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pyarrow/array.pxi:889\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pyarrow/table.pxi:5132\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pyarrow/pandas_compat.py:808\u001b[0m, in \u001b[0;36mtable_to_dataframe\u001b[0;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[1;32m    805\u001b[0m columns \u001b[38;5;241m=\u001b[39m _deserialize_column_index(table, all_columns, column_indexes)\n\u001b[1;32m    807\u001b[0m column_names \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcolumn_names\n\u001b[0;32m--> 808\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable_to_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mext_columns_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _pandas_api\u001b[38;5;241m.\u001b[39mis_ge_v3():\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_dataframe_from_blocks\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === 1. Load raw data ===\n",
    "print(\"üì• Lade Rohdaten...\")\n",
    "df = pd.read_parquet('/home/jovyan/AICOMP/Second/code/data/raw/train_series.parquet')\n",
    "train_events = pd.read_csv('/home/jovyan/AICOMP/Second/code/data/raw/train_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21dc4d7-04fc-4360-a49e-e2183da81214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Timestamp-Conversion in Batches ===\n",
    "print(\"üîÑ Konvertiere Timestamp-Spalte...\")\n",
    "total_rows = len(df)\n",
    "batch_size = 1_000_000\n",
    "for i in range(0, total_rows, batch_size):\n",
    "    start = i\n",
    "    end = min(i + batch_size, total_rows)\n",
    "    df.iloc[start:end, df.columns.get_loc('timestamp')] = pd.to_datetime(\n",
    "        df.iloc[start:end, df.columns.get_loc('timestamp')], utc=True\n",
    "    )\n",
    "    print(f\"Pocessed rows {start + 1} bis {end}... ({(end / total_rows) * 100:.2f}% finished)\")\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "df.to_parquet('/home/jovyan/AICOMP/code/data/processed/train_series_cleaned.parquet', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860ba32-18fe-412a-bbcb-8f46fb77cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Load data with ===\n",
    "df_cleaned = pd.read_parquet('/home/jovyan/AICOMP/code/data/processed/train_series_cleaned.parquet')\n",
    "\n",
    "train_events['timestamp'] = pd.to_datetime(train_events['timestamp'], utc=True)\n",
    "train_events = train_events.drop_duplicates()\n",
    "train_events = train_events.dropna(subset=['timestamp'])\n",
    "train_events = train_events.sort_values(by=[\"series_id\", \"step\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c657fe-d103-4e29-9d32-b8c4e3d763f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Remove series_ids with gaps in the nights and step===(where there are nights missing there are also missing timestamps)\n",
    "print(\"üßπ Removing series_ids with night gaps...\")\n",
    "gaps = []\n",
    "\n",
    "# Group by series_id and check for missing nights\n",
    "for series_id, group in train_events.groupby(\"series_id\"):\n",
    "    group = group.sort_values(by=\"step\")\n",
    "    nights_with_data = group[group[\"step\"].notna()][\"night\"].unique()\n",
    "    max_night = group[\"night\"].max()\n",
    "    all_nights = set(range(1, max_night + 1))\n",
    "    missing_nights = all_nights - set(nights_with_data)\n",
    "    if missing_nights:\n",
    "        print(f\"üö® {series_id} has gaps in nights {sorted(missing_nights)}!\")\n",
    "        gaps.append(series_id)\n",
    "\n",
    "# Report result\n",
    "if not gaps:\n",
    "    print(\"No gaps found!\")\n",
    "removed_ids = len(gaps)\n",
    "print(f\" {removed_ids:,} series_ids removed due to night gaps.\")\n",
    "print(f\"Before: {df_cleaned.shape[0]} rows\")\n",
    "df_cleaned = df_cleaned[~df_cleaned[\"series_id\"].isin(gaps)]\n",
    "print(f\"After: {df_cleaned.shape[0]} rows\")\n",
    "\n",
    "# Remove from original events as well\n",
    "event_cleaned = train_events[~train_events[\"series_id\"].isin(gaps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b92df-20bd-4293-92a1-0da01ba2101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = \"/home/jovyan/AICOMP/Second/code/data/raw/event_cleaned.csv\"\n",
    "event_cleaned.to_csv(fi, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe9bd29-b5b3-4ffa-b0c2-388c177dc822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all series ids from train dataset which dont are in event dataset\n",
    "print(f\"Before: {len(df_cleaned)} rows\")\n",
    "df_cleaned = df_cleaned[df_cleaned['series_id'].isin(train_events['series_id'])]\n",
    "print(f\"After: {len(df_cleaned)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce1f64-64f7-47df-b35c-b196464eb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_cleaned['event'].value_counts().loc[['onset', 'wakeup']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da58850-ca03-4398-84a8-893cbd27198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Remove unnecessary steps in train dataset where we dont have any data in the event dataset ===\n",
    "print(\"üîç Filtering steps outside event boundaries...\")\n",
    "max_steps = train_events.groupby(\"series_id\")[\"step\"].max().to_dict()\n",
    "df_cleaned = df_cleaned[\n",
    "    df_cleaned.apply(lambda row: row[\"step\"] <= max_steps.get(row[\"series_id\"], float('inf')), axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66d96e-df33-45a8-a96f-ca3f5fe7e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Merge\n",
    "merged_dff = pd.merge(df_cleaned, train_events, on=['series_id', 'timestamp'], how='left')\n",
    "\n",
    "# 2. Store the positions of the original events\n",
    "original_mask = merged_dff[\"event\"].notna()\n",
    "\n",
    "# 3. Forward-fill the 'event' and 'night' columns within each series_id\n",
    "merged_dff[[\"night\", \"event\"]] = merged_dff.groupby(\"series_id\")[[\"night\", \"event\"]].ffill()\n",
    "\n",
    "# 4. Fill initial NaNs (before the first event)\n",
    "merged_dff[\"event\"] = merged_dff[\"event\"].fillna(\"wakeup\") #because the first event is always onset so the people are awake when the timeseries starts\n",
    "merged_dff[\"night\"] = merged_dff[\"night\"].fillna(0)\n",
    "\n",
    "# 5. Replace only the filled values with asleep/awake, not the original ones\n",
    "filled_mask = ~original_mask\n",
    "merged_dff.loc[filled_mask & (merged_dff[\"event\"] == \"wakeup\"), \"event\"] = \"awake\"\n",
    "merged_dff.loc[filled_mask & (merged_dff[\"event\"] == \"onset\"), \"event\"] = \"asleep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffdafd-1ce2-4350-8576-a13a7533944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"'onset' count: {(merged_dff['event'] == 'onset').sum():,}\")\n",
    "print(f\"'wakeup' count: {(merged_dff['event'] == 'wakeup').sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30433259-7a59-49e8-83b1-67be52f867c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"'awake' count: {(merged_dff['event'] == 'awake').sum():,}\")\n",
    "print(f\"'asleep' count: {(merged_dff['event'] == 'asleep').sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1046b59-bb4a-4a90-b2f5-117ff18f9c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate 'step_y' column \n",
    "if \"step_y\" in merged_dff.columns:\n",
    "    merged_dff.drop(columns=[\"step_y\"], inplace=True)\n",
    "\n",
    "# Rename 'step_x' back to 'step' \n",
    "if \"step_x\" in merged_dff.columns:\n",
    "    merged_dff.rename(columns={\"step_x\": \"step\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6141b04-d084-46bc-9871-7ef3b65fd89b",
   "metadata": {},
   "source": [
    "#Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ce423-7212-4702-8cc0-cdd280bcadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8. Time-based features ===\n",
    "merged_dff['hour'] = merged_dff['timestamp'].dt.hour.astype('int8')\n",
    "merged_dff['minute'] = merged_dff['timestamp'].dt.minute.astype('int8')\n",
    "merged_dff['day_of_week'] = merged_dff['timestamp'].dt.dayofweek.astype('int8')\n",
    "merged_dff['elapsed_time_from_midnight'] = (merged_dff['hour'] * 60 + merged_dff['minute']).astype('int32')\n",
    "merged_dff['is_weekend'] = (merged_dff['day_of_week'] >= 5).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d962d7c-9db3-47ff-ad52-38722aa5e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d327d-7c7f-473e-964c-d6cfbfa7102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Calculating rolling statistical features...\")\n",
    "window_sizes = [12, 60, 360]  # in 5-second steps\n",
    "for window in window_sizes:\n",
    "    for col in ['anglez', 'enmo']:\n",
    "        merged_dff[f'{col}_mean_{window}s'] = merged_dff[col].rolling(window, min_periods=1).mean().astype('float32')\n",
    "        merged_dff[f'{col}_std_{window}s'] = merged_dff[col].rolling(window, min_periods=1).std().astype('float32')\n",
    "        merged_dff[f'{col}_min_{window}s'] = merged_dff[col].rolling(window, min_periods=1).min().astype('float32')\n",
    "        merged_dff[f'{col}_max_{window}s'] = merged_dff[col].rolling(window, min_periods=1).max().astype('float32')\n",
    "        merged_dff[f'{col}_median_{window}s'] = merged_dff[col].rolling(window, min_periods=1).median().astype('float32')\n",
    "        merged_dff[f'{col}_cumulative_{window}s'] = merged_dff[col].rolling(window, min_periods=1).sum().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411794f5-2ba6-42aa-b63c-ba6f5028ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce879c1a-25af-4d33-a24c-ab6c1b7be3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 9. Advanced Feature Engineering ===\n",
    "print(\"üß† Adding more meaningful features...\")\n",
    "\n",
    "# is_night (as int8 for binary flag)\n",
    "merged_dff[\"is_night\"] = ((merged_dff[\"hour\"] >= 22) | (merged_dff[\"hour\"] <= 6)).astype('int8')\n",
    "\n",
    "# anglez_delta (as float32 to save memory)\n",
    "merged_dff[\"anglez_delta\"] = (merged_dff[\"anglez\"] - merged_dff[\"anglez\"].shift(1)).astype('float32')\n",
    "\n",
    "# SMA of enmo (Simple Moving Average), cast to float32\n",
    "sma_windows = [12, 60, 360]\n",
    "for window in sma_windows:\n",
    "    merged_dff[f'enmo_sma_{window}s'] = merged_dff['enmo'].rolling(window, min_periods=1).mean().astype('float32')\n",
    "\n",
    "# Lag Features (cast to float32 for efficiency)\n",
    "lag_targets = [\n",
    "    \"anglez\", \"enmo\",\n",
    "    \"anglez_mean_12s\", \"anglez_std_12s\",\n",
    "    \"enmo_mean_12s\", \"enmo_std_12s\",\n",
    "    \"anglez_mean_60s\", \"anglez_std_60s\",\n",
    "    \"enmo_mean_60s\", \"enmo_std_60s\"\n",
    "]\n",
    "lag_steps = [1, 2, 3]\n",
    "for col in lag_targets:\n",
    "    for lag in lag_steps:\n",
    "        merged_dff[f\"{col}_lag_{lag}\"] = merged_dff[col].shift(lag).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b88d4a-bf89-4908-bfc2-cd3cad4973fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaNs\n",
    "na_cols = merged_dff.columns[merged_dff.isna().any()]\n",
    "\n",
    "# Fill only numeric columns with their median\n",
    "for col in na_cols:\n",
    "    if pd.api.types.is_numeric_dtype(merged_dff[col]):\n",
    "        merged_dff[col] = merged_dff[col].fillna(merged_dff[col].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70818289-7387-4c86-85c1-890b8be717ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Noch NaNs √ºbrig?\")\n",
    "print(merged_dff.isna().sum()[merged_dff.isna().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5ef74-c358-4f04-9566-f165223257ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dff.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a926ab-74b4-4aa9-91e9-365353daeaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 10. Zielvariablen umkodieren ===\n",
    "event_mapping = {\n",
    "    \"asleep\": 0,\n",
    "    \"awake\": 1,\n",
    "    \"onset\": 2,\n",
    "    \"wakeup\": 3\n",
    "}\n",
    "merged_dff[\"event\"] = merged_dff[\"event\"].map(event_mapping)\n",
    "\n",
    "# Binary Target f√ºr Klassifikation: onset & wakeup = 1\n",
    "merged_dff[\"target\"] = merged_dff[\"event\"].apply(lambda x: 1 if x in [2, 3] else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40156eb0-a2b2-403c-8998-9c03c93d27f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 11. Speichern ===\n",
    "final_output = \"/home/jovyan/AICOMP/code/data/processed/merged_dff_gold84_V3.parquet\"\n",
    "merged_dff.to_parquet(final_output, index=False)\n",
    "print(f\"‚úÖ Finales Preprocessed Dataset gespeichert unter: {final_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b256c-b87f-4e89-aedf-42046941f621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

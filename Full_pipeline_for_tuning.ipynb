{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf45e631-67c5-4f01-a704-326126889246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, average_precision_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n",
    "from event_detection_ap import score, ParticipantVisibleError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5db770-ef45-482e-ae5d-858daa62a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"processed/final_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2be55b2-b283-4ed7-a2fe-b7e9dbce076f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23060846"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d8d11eb-736d-4869-aefe-d784bcb388a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    print(\"üîÑ Starting feature generation...\")\n",
    "\n",
    "    # === 1. Convert timestamp to datetime and remove timezone ===\n",
    "    print(\"üïí Converting timestamp to datetime...\")\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']).apply(lambda t: t.tz_localize(None))\n",
    "\n",
    "    # === 2. Hour-based features ===\n",
    "    print(\"‚è∞ Generating time-based features...\")\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour.astype('int8')\n",
    "    df[\"minute\"] = df[\"timestamp\"].dt.minute.astype('int8')\n",
    "    df[\"day_of_week\"] = df[\"timestamp\"].dt.dayofweek.astype('int8')\n",
    "    df[\"elapsed_time_from_midnight\"] = (df[\"hour\"] * 60 + df[\"minute\"]).astype('int32')\n",
    "    df[\"is_weekend\"] = (df[\"day_of_week\"] >= 5).astype('int8')\n",
    "    df[\"is_night\"] = ((df[\"hour\"] >= 22) | (df[\"hour\"] <= 6)).astype('int8')\n",
    "\n",
    "    # === 3. Time-based features ===\n",
    "    print(\"üìà Calculating time-differential features...\")\n",
    "    periods = 20\n",
    "    df[\"anglez\"] = abs(df[\"anglez\"])\n",
    "    df[\"anglez_diff\"] = df.groupby('series_id')['anglez'].diff(periods=periods).bfill().astype('float16')\n",
    "    df[\"enmo_diff\"] = df.groupby('series_id')['enmo'].diff(periods=periods).bfill().astype('float16')\n",
    "\n",
    "    # === 4. Rolling statistical features (mean, max, std, etc.) ===\n",
    "    print(\"üîÅ Computing rolling statistics...\")\n",
    "    window_sizes = [12, 100, 360]\n",
    "    for window in window_sizes:\n",
    "        print(f\"  ‚û§ Rolling features for window size: {window}\")\n",
    "        for col in ['anglez', 'enmo']:\n",
    "            df[f'{col}_mean_{window}s'] = df[col].rolling(window, min_periods=1).mean().astype('float16')\n",
    "            df[f'{col}_std_{window}s'] = df[col].rolling(window, min_periods=1).std().astype('float16')\n",
    "            df[f'{col}_min_{window}s'] = df[col].rolling(window, min_periods=1).min().astype('float16')\n",
    "            df[f'{col}_max_{window}s'] = df[col].rolling(window, min_periods=1).max().astype('float16')\n",
    "            df[f'{col}_median_{window}s'] = df[col].rolling(window, min_periods=1).median().astype('float16')\n",
    "            df[f'{col}_cumulative_{window}s'] = df[col].rolling(window, min_periods=1).sum().astype('float16')\n",
    "\n",
    "\n",
    "    # === 6. Lag Features ===\n",
    "    print(\"‚è™ Adding lag features...\")\n",
    "    lag_targets = [\n",
    "        \"anglez\", \"enmo\",\n",
    "        \"anglez_mean_12s\", \"anglez_std_12s\",\n",
    "        \"enmo_mean_12s\", \"enmo_std_12s\",\n",
    "        \"anglez_mean_100s\", \"anglez_std_100s\",\n",
    "        \"enmo_mean_100s\", \"enmo_std_100s\"\n",
    "    ]\n",
    "    lag_steps = [1, 2, 3]\n",
    "    for col in lag_targets:\n",
    "        for lag in lag_steps:\n",
    "            df[f\"{col}_lag_{lag}\"] = df[col].shift(lag).astype('float16')\n",
    "\n",
    "    # === 7. Handle NaN values ===\n",
    "    print(\"üßπ Filling missing values...\")\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    df[numeric_cols] = df[numeric_cols].astype('float32').bfill().ffill().astype(df[numeric_cols].dtypes.to_dict())\n",
    "\n",
    "    print(\"‚úÖ Feature generation complete. Total features:\", len(df.columns))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b28025a8-a4a5-47f8-9757-0d10e2e5e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = [\n",
    "    \"hour\", \"anglez_mean_100s\", \"anglez_std_100s\", \"anglez_diff\",\n",
    "    \"enmo\", \"enmo_mean_100s\", \"enmo_max_100s\", \"enmo_std_100s\", \"enmo_diff\"\n",
    "]\n",
    "\n",
    "extended_features1 = base_features + [\n",
    "    \"anglez_mean_360s\", \"anglez_std_360s\",\n",
    "    \"enmo_std_360s\", \"is_night\", \"is_weekend\"\n",
    "]\n",
    "\n",
    "extended_features2 = base_features + [\n",
    "    \n",
    "    # Lag features\n",
    "    \"anglez_std_100s_lag_3\",\n",
    "    \"anglez_std_100s_lag_2\",\n",
    "    \"anglez_std_100s_lag_1\",\n",
    "    \"enmo_mean_100s_lag_1\",\n",
    "    \"enmo_mean_100s_lag_2\",\n",
    "    \"enmo_mean_100s_lag_3\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc4fb2a-fa9a-461d-86b4-10f075880147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Starting feature generation...\n",
      "üïí Converting timestamp to datetime...\n",
      "‚è∞ Generating time-based features...\n",
      "üìà Calculating time-differential features...\n",
      "üîÅ Computing rolling statistics...\n",
      "  ‚û§ Rolling features for window size: 12\n",
      "  ‚û§ Rolling features for window size: 100\n",
      "  ‚û§ Rolling features for window size: 360\n",
      "‚è™ Adding lag features...\n",
      "üßπ Filling missing values...\n",
      "‚úÖ Feature generation complete. Total features: 80\n"
     ]
    }
   ],
   "source": [
    "train = make_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe691e12-2d9a-4f06-9651-34e5ad0508e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showcor(X):\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(X.corr(), annot=True, fmt=\".2f\", cmap='coolwarm', center=0)\n",
    "    plt.title(\"Feature Correlation Heatmap (with values)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "805ff900-6251-4e1f-81f7-60d387d444f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv_random_forest(train_df, features, n_splits=3, model_params=None):\n",
    "    if model_params is None:\n",
    "        model_params = {\n",
    "            'n_estimators': 100,\n",
    "            'min_samples_leaf': 300,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "\n",
    "    X = train_df[features]\n",
    "    y = train_df[\"awake\"]\n",
    "    groups = train_df[\"series_id\"]\n",
    "\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    oof_preds_not_awake = np.zeros(len(X))\n",
    "    feature_importances = np.zeros(X.shape[1])\n",
    "    fold_metrics = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "        print(f\"\\nüîÅ Fold {fold + 1}\")\n",
    "        print(f\"  ‚û§ Training size: {len(train_idx)} | Validation size: {len(val_idx)}\")\n",
    "\n",
    "        X_tr, y_tr = X.iloc[train_idx].copy(), y.iloc[train_idx].copy()\n",
    "        X_val, y_val = X.iloc[val_idx].copy(), y.iloc[val_idx].copy()\n",
    "\n",
    "        model = RandomForestClassifier(**model_params)\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        probs = model.predict_proba(X_val)\n",
    "        preds = model.predict(X_val)\n",
    "\n",
    "        oof_preds[val_idx] = probs[:, 1]\n",
    "        oof_preds_not_awake[val_idx] = probs[:, 0]\n",
    "\n",
    "        precision = precision_score(y_val, preds)\n",
    "        recall = recall_score(y_val, preds)\n",
    "        f1 = f1_score(y_val, preds)\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'fold': fold + 1,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        })\n",
    "\n",
    "        print(f\"  üìà Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "        feature_importances += model.feature_importances_\n",
    "\n",
    "    avg_importances = feature_importances / n_splits\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': avg_importances\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    metrics_df = pd.DataFrame(fold_metrics)\n",
    "    print(\"\\nüìä Fold-wise metrics:\\n\", metrics_df)\n",
    "    print(f\"\\nüîç Mean F1 Score: {metrics_df['f1_score'].mean():.4f}\")\n",
    "\n",
    "    print(\"\\nüî• Top 10 Feature Importances:\")\n",
    "    print(importance_df.head(10))\n",
    "\n",
    "    return oof_preds, oof_preds_not_awake, model, X.columns, importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b563fdf6-4e11-47fe-bd80-0ffcb0bbb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_predictions(df, awake_col=\"awake_pred\", not_awake_col=\"not_awake_pred\", smoothing_length=460):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df[\"score\"] = df[awake_col].rolling(smoothing_length, center=True).mean().bfill().ffill()\n",
    "    df[\"smooth\"] = df[not_awake_col].rolling(smoothing_length, center=True).mean().bfill().ffill()\n",
    "    \n",
    "    df[\"smooth\"] = df[\"smooth\"].round()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd6a550d-1404-477a-9d1a-2c64e670001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the function to determine the onset and wakeup events\n",
    "def get_event(df):\n",
    "    lstCV = zip(df.series_id, df.smooth)\n",
    "    lstPOI = []\n",
    "    for (c, v), g in groupby(lstCV, lambda cv: (cv[0], cv[1] != 0 and not pd.isnull(cv[1]))):\n",
    "        llg = sum(1 for item in g)\n",
    "        if v is False:\n",
    "            lstPOI.extend([0] * llg)\n",
    "        else:\n",
    "            lstPOI.extend(['onset'] + (llg - 2) * [0] + ['wakeup'] if llg > 1 else [0])\n",
    "    return lstPOI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80373f34-203d-4ebb-8d14-1392a68908d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_filter(result_events, step_diff_min):\n",
    "    df = pd.DataFrame(result_events)\n",
    "    \n",
    "    # Set a threshold for valid pairings (step difference > 15000 is invalid)\n",
    "    step_diff_min_threshold = step_diff_min\n",
    "    \n",
    "    # Sort by series_id and step\n",
    "    df = df.sort_values(by=['series_id', 'step'])\n",
    "    \n",
    "    # Initialize a list to store valid event pairs\n",
    "    valid_pairs = []\n",
    "    \n",
    "    # Iterate through each unique series_id and match onsets and wakeups\n",
    "    for series_id in df['series_id'].unique():\n",
    "        series_data = df[df['series_id'] == series_id]\n",
    "        \n",
    "        onset_event = None\n",
    "        for index, row in series_data.iterrows():\n",
    "            if row['event'] == 'onset':\n",
    "                onset_event = row\n",
    "            elif row['event'] == 'wakeup' and onset_event is not None:\n",
    "                # Ensure the step difference between onset and wakeup is above the minimum threshold\n",
    "                step_diff = abs(row['step'] - onset_event['step'])\n",
    "                if step_diff >= step_diff_min_threshold:\n",
    "                    valid_pairs.append((onset_event, row))  # Add the valid pair\n",
    "                onset_event = None  # Reset for next pairing\n",
    "    \n",
    "    # Create a DataFrame for the valid pairs in the required format\n",
    "    output_data = []\n",
    "    for onset, wakeup in valid_pairs:\n",
    "        output_data.append({\n",
    "            'series_id': onset['series_id'],\n",
    "            'step': onset['step'],\n",
    "            'event': 'onset',\n",
    "            'score': onset['score']\n",
    "        })\n",
    "        output_data.append({\n",
    "            'series_id': wakeup['series_id'],\n",
    "            'step': wakeup['step'],\n",
    "            'event': 'wakeup',\n",
    "            'score': wakeup['score']\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame from the output data\n",
    "    output_df = pd.DataFrame(output_data)\n",
    "    \n",
    "    # Save the results to a CSV file\n",
    "    output_df.to_csv('valid_pairs_predictions.csv', index=False)\n",
    "    \n",
    "    print(\"Results saved to 'valid_pairs_predictions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9fdb32-8c36-46c1-a9c8-8e8529ccffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_full_pipeline():\n",
    "\n",
    "\n",
    "    # Load ground truth and predictions\n",
    "    solution = pd.read_csv('processed/event_cleaned_final.csv')             # Ground truth\n",
    "    submission = pd.read_csv('valid_pairs_predictions.csv')                      # Your predictions from train set\n",
    "    \n",
    "    # Define tolerances\n",
    "    tolerances = {\n",
    "        \"onset\":  [12, 36, 60, 90, 120, 150, 180, 240, 300, 360],\n",
    "        \"wakeup\": [12, 36, 60, 90, 120, 150, 180, 240, 300, 360],\n",
    "    }\n",
    "    \n",
    "    # Set correct column names used in your prediction file\n",
    "    column_names = {\n",
    "        'series_id_column_name': 'series_id',\n",
    "        'time_column_name': 'step',\n",
    "        'event_column_name': 'event',\n",
    "        'score_column_name': 'score',  # You named the prediction confidence 'score'\n",
    "    }\n",
    "    \n",
    "    # Run scoring\n",
    "    try:\n",
    "        ap_score = score(solution, submission, tolerances, **column_names)\n",
    "        print(f\"\\n‚úÖ Average Precision Score: {ap_score}\")\n",
    "    except ParticipantVisibleError as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "\n",
    "\n",
    "    return ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6c1a080-0f1a-4ee5-b226-5a2c162d5806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model, feature_names, top_n=None, save_path=None, title=\"Feature Importances\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    feat_df = pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"importance\": importances\n",
    "    }).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "    if top_n:\n",
    "        feat_df = feat_df.head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feat_df[\"feature\"], feat_df[\"importance\"])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_path:\n",
    "        feat_df.to_csv(save_path, index=False)\n",
    "        print(f\"üìÅ Feature importances saved to: {save_path}\")\n",
    "    \n",
    "    return feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaf7ff6d-1516-4795-b72d-5bc59356a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pipeline(train, features, step_diff_min=2000, smoothing_length=460, n_splits=3, model_params=None):\n",
    "    print(\"üöÄ Starting full pipeline...\")\n",
    "\n",
    "    train_df = train\n",
    "\n",
    "    oof_preds, oof_preds_not_awake, model, cols, importances = run_cv_random_forest(\n",
    "        train_df, features, n_splits=n_splits, model_params=model_params\n",
    "    )\n",
    "    plot_feature_importances(model, cols, top_n=15, save_path=\"feature_importances.csv\")\n",
    "\n",
    "    train_df[\"awake_pred\"] = oof_preds\n",
    "    train_df[\"not_awake_pred\"] = oof_preds_not_awake\n",
    "\n",
    "    # üëá Pass smoothing_length here\n",
    "    train_df = smooth_predictions(train_df, smoothing_length=smoothing_length)\n",
    "\n",
    "    train_df[\"event\"] = get_event(train_df)\n",
    "    train_events = train_df.loc[train_df[\"event\"] != 0, [\"series_id\", \"step\", \"event\", \"score\"]].reset_index(drop=True)\n",
    "    train_events.to_csv('result_events.csv', index=False)\n",
    "    print(\"\\n‚úÖ Events saved to: result_events.csv\")\n",
    "\n",
    "    apply_filter(train_events, step_diff_min=step_diff_min)\n",
    "    ap_score = evaluate_full_pipeline()\n",
    "\n",
    "    return ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d10366-7104-4b00-82f2-4387d51122ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a633aab2-d385-42ac-b2dc-85aade53e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "\n",
    "def parameter_sweep_with_features(\n",
    "    train,\n",
    "    feature_sets,\n",
    "    param_grid,\n",
    "    step_diff_min_values=[2000],\n",
    "    smoothing_lengths=[460],\n",
    "    n_splits=3,\n",
    "    result_csv_path=\"sweep_results.csv\"\n",
    "):\n",
    "    results = []\n",
    "    default_params = {\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    keys, values = zip(*param_grid.items())\n",
    "\n",
    "    # Initialize CSV file with header if it doesn't exist\n",
    "    try:\n",
    "        existing_df = pd.read_csv(result_csv_path)\n",
    "        print(f\"üìÑ Appending to existing result file: {result_csv_path}\")\n",
    "    except FileNotFoundError:\n",
    "        pd.DataFrame(columns=[\n",
    "            'timestamp', 'feature_set', 'features', 'params',\n",
    "            'step_diff_min', 'smoothing_length', 'ap_score'\n",
    "        ]).to_csv(result_csv_path, index=False)\n",
    "        print(f\"üìÑ Created new result file: {result_csv_path}\")\n",
    "\n",
    "    for feature_set_name, feature_list in feature_sets.items():\n",
    "        print(f\"\\nüß™ Testing feature set: {feature_set_name}\")\n",
    "        for step_diff_min in step_diff_min_values:\n",
    "            for smoothing_length in smoothing_lengths:\n",
    "                for comb in product(*values):\n",
    "                    sweep_params = dict(zip(keys, comb))\n",
    "                    model_params = {**default_params, **sweep_params}\n",
    "\n",
    "                    print(f\"\\nüîç Running with smoothing={smoothing_length}, step_diff_min={step_diff_min}, params={model_params}\")\n",
    "\n",
    "                    try:\n",
    "                        ap_score = main_pipeline(\n",
    "                            train=train,\n",
    "                            features=feature_list,\n",
    "                            step_diff_min=step_diff_min,\n",
    "                            smoothing_length=smoothing_length,\n",
    "                            n_splits=n_splits,\n",
    "                            model_params=model_params\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Failed: {e}\")\n",
    "                        ap_score = None\n",
    "\n",
    "                    result = {\n",
    "                        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        'feature_set': feature_set_name,\n",
    "                        'features': ', '.join(feature_list),\n",
    "                        'params': model_params,\n",
    "                        'step_diff_min': step_diff_min,\n",
    "                        'smoothing_length': smoothing_length,\n",
    "                        'ap_score': ap_score\n",
    "                    }\n",
    "\n",
    "                    # Append to results list\n",
    "                    results.append(result)\n",
    "\n",
    "                    # Write result row to CSV immediately\n",
    "                    pd.DataFrame([result]).to_csv(result_csv_path, mode='a', index=False, header=False)\n",
    "                    print(f\"üì§ Saved result to {result_csv_path}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(by='ap_score', ascending=False)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ddd9f-3b08-4155-9274-99fa6b1a5664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Created new result file: sweep_results.csv\n",
      "\n",
      "üß™ Testing feature set: extended1\n",
      "\n",
      "üîç Running with smoothing=300, step_diff_min=1500, params={'random_state': 42, 'n_jobs': -1, 'n_estimators': 100, 'min_samples_leaf': 300}\n",
      "üöÄ Starting full pipeline...\n",
      "\n",
      "üîÅ Fold 1\n",
      "  ‚û§ Training size: 15330629 | Validation size: 7730217\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'min_samples_leaf': [300]\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "    \n",
    "    \"extended1\": extended_features1,\n",
    "    \"extended2\": extended_features2,\n",
    "    \n",
    "}\n",
    "\n",
    "sweep_results = parameter_sweep_with_features(\n",
    "    train=train,\n",
    "    feature_sets=feature_sets,\n",
    "    param_grid=param_grid,\n",
    "    step_diff_min_values=[1500, 2000, 2500],\n",
    "    smoothing_lengths=[300, 460, 600],\n",
    "    result_csv_path=\"sweep_results.csv\"\n",
    ")\n",
    "\n",
    "print(sweep_results[['feature_set', 'smoothing_length', 'step_diff_min', 'params', 'ap_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15939d51-0b39-42cf-8ce3-09df9c92df1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1443969-3f9c-4c55-9eba-4f271fd6d9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
